#需要使用的软件
FastQC, Trimmomatic, FLASH, megahit, bowtie2/bwa/hisat2, samtools, bedtools, Metaphlan2, kraken, Prokka, MaxBin, FragGeneScan
idba, Metabat
#原理介绍:宏基因组总体分为基于16S/18S或ITS测序分析或基于denovo的测序分析。前者主要用于微生物的多样性、鉴定分析。后者主要用于病毒、未知微生物的分析。
通常情况下，病毒的宏基因组分析也叫宏病毒组。宏基因组分析流程大致为：将数据质控过滤后，去除宿主基因组（环境样本不用去除），再根据overlap或者contigs拼接
将拼接的序列进行去冗余或者去嵌合体分析，构建基因集合。再将冗余的原始reads比对至非冗余基因集合，确定丰度信息。最后将组装的长序列结合丰度信息进行物种鉴定。
#软件安装：
1.Maxbin
curl  https://downloads.jbei.org/data/microbial_communities/MaxBin/getfile.php?MaxBin-2.2.2.tar.gz > MaxBin-2.2.2.tar.gz
tar -xzvf MaxBin-2.2.2.tar.gz
cd MaxBin-2.2.2/src
make
echo 'PATH=$PATH:~/softwar/MaxBin-2.2.2' >> ~/.bashrc
source ~/.bashrc

2.FragGeneScan
git clone https://github.com/COL-IU/FragGeneScan.git
cd FragGeneScan
make clean
make fgs
echo 'PATH=$PATH:~/softwar/FragGeneScan' >> ~/.bashrc
source ~/.bashrc

3.idba
git clone https://github.com/loneknightpy/idba.git
cd idba
./build.sh
echo 'PATH=$PATH:~/softwar/idba/bin' >> ~/.bashrc
source ~/.bashrc

4.Metabat2
conda install -c ursky metabat2

#分析流程
本次采用联合国分析项目中的５个汉堡宏基因组测序数据为例子。目的是鉴定是否存在要求的30多中细菌。拿到fastq测序数据
1.直接使用Trimmomatic过滤低质量数据
for i in `seq 1 5`
do 
java -jar ~/softwar/Trimmomatic-0.38/trimmomatic-0.38.jar PE -threads 12 -phred33 
PT2-00${i}_R1.fq.gz PT2-00${i}_R2.fq.gz PT2-00${i}_1_paired.fastq.gz PT2-00${i}_1_unpaired.fastq.gz 
PT2-00${i}_2_paired.fastq.gz PT2-00${i}_2_unpaired.fastq.gz 
ILLUMINACLIP:~/softwar/Trimmomatic-0.38/adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:51
done

2.将过滤好的数据使用megahit拼接contigs#由于是环境样本，其中不存在宿主基因组，所以不用过滤宿主基因组
for i in `seq 1 5`
do
megahit -t 24 -m 0.5 -1 PT2-00${i}_1_paired.fastq.gz -2 PT2-00${i}_2_paired.fastq.gz -o Burger${i}
done

如果样本是诸如肠道、血液等宏基因组测序数据，需要过滤宿主基因组。以本项目中的Spinach宏基因组测序样本为例
在NCBI的Genome中下载Spinach的基因组序列
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/002/007/265/GCF_002007265.1_ASM200726v1/GCF_002007265.1_ASM200726v1_genomic.fna.gz
gzip -d GCF_002007265.1_ASM200726v1_genomic.fna.gz #解压
mv GCF_002007265.1_ASM200726v1_genomic.fna Spinach_genomic.fna　＃重命名
接下来需要对该基因组建立索引，用于比对reads至基因组索引。比对的软件较多，bwa, bowtie, hisat2均可。
以bwa为例：
bwa index Spinach_genomic.fna　#建立索引,生成带有Spinach_genomic.fna前缀的索引文件
for i in `seq 13 14`
do
bwa mem Spinach_genomic.fna　PT2-0${i}_1_paired.fastq.gz PT2-0${i}_2_paired.fastq.gz > map_0${i}_Spinach.sam
done
输出的.sam文件中包含了比对的所有信息，我们可以根据.sam文件的信息提取出未比对上的序列，由于sam文件的储存空间大，需要将sam转化为bam加快分析
for i in `seq 13 14`
do 
samtools view -b map_0${i}_Spinach.sam > map_0${i}_Spinach.bam　
samtools view -b -f 4 map_0${i}_Spinach.bam > unmap_0${i}_Spinach.bam
done
# -f 4代表获得未比对上的序列，如果要提取比对上的序列用-F 4，另外数字４用于paird end测序，数字把用于mate paird测序
提取出未比对上的reads的bam文件后，需要将bam文件中的fastq格式文件,使用bam2fastq软件提取fastq格式数据
bam2fastq --unaligned unmap_014_Spinach.bam -o Spinach#.fastq
＃Spinach#.fastq中的#代表输出的是双端测序fastq数据(由于原始测序数据是双端测序)
综上，我们得到了去掉宿主基因组的fastq文件，后续的操作重复２中的megahit拼接流程。

3.Binning分析
3.1 Binning原理介绍
前面，我们根据contigs拼接到得到了较长序列的数据，但是这些序列是杂乱的，我们无法区分哪些序列来自于同一细菌或病毒，Binning的目的在于将这些杂乱的
序列通过聚类的方法分类为一个细菌或病毒一组序列。就好像乐高玩具中把不同颜色的单元按照颜色分类至一起。对于细菌或者病毒的分类通常基于核酸使用频率、G
C含量、或者序列分布的丰度信息进行分类。简要阐明：不同的细菌或者病毒四种碱基的使用频率或者GC含量是不一样的，根据序列的４碱基使用频率和GC含量的相似
性可以将不同的序列分类到一个细菌或者病毒中。另外，相关文献中说明对于不同的样本，微生物分布的丰度不同，从而导致基因的丰度不同，反之，根据序列的丰度差
异可以将不同序列分类至一个细菌或病毒。通常情况下，前者方法更适合于长序列的分析。我们已经组装了相对较长的序列。所以可以通过将该拼接的序列信息建立索引，
进而将reads再次比对至拼接序列的索引，统计丰度信息．最后，通过该丰度信息将拼接的序列进行分类。

3.2 丰度信息的统计
bwa index Spinach.final.contigs.fa
bwa mem Spinach.final.contigs.fa Spinach_1.fastq Spinach_2.fastq > Spinach.sam
samtools view -b Spinach.sam > Spinach.bam
samtools -b sort Spinach.bam > Spinach.sorted.bam #排序
genomeCoverageBed -ibam Spinach.sorted.bam > Spinach.histogram.tab　＃使用bedtools统计reads比对上索引的丰度信息
wget https://raw.githubusercontent.com/ngs-docs/2017-cicese-metagenomics/master/files/calculate-contig-coverage.py
python calculate-contig-coverage.py Spinach.histogram.tab #使用下载的脚本对于序列进行定量
ls Spinach.histogram.tab.coverage.tab > Spinach_abundance.list #将定量后的丰度信息文件名传递至列表格式文件中

3.3 Binning
~/softwar/MaxBin-2.2.2/run_MaxBin.pl -contig Spinach.final.contigs.fa -abund_list Spinach_abundance.list -max_iteration 5
-out Spinach_Maxbin #使用MaxBin中的perl脚本将拼接的序列结合丰度信息文件进行分析依据丰度信息分类序列，将预测的bins序列以不同的fasta文件输出

for file in Spinach_Maxbin.*.fasta
do
num=${file//[!0-9]/}
sed -e "/^>/ s/$/ ${num}/" Spinach_Maxbin.$num.fasta >> Spinach_Maxbin_binned.concat.fasta
done #将不同的bins进行合并

#生成可视化的列表用VizBin软件打开可视化
echo label > Spinach_Maxbin_annotation.list
grep ">" Spinach_Maxbin_binned.concat.fasta |cut -f2 -d ' '>> Spinach_Maxbin_annotation.list

＃VizBin安装
sudo apt-get install libatlas3-base libopenblas-base default-jre
curl -L https://github.com/claczny/VizBin/blob/master/VizBin-dist.jar?raw=true > VizBin-dist.jar

3.4 初步鉴定细菌或病毒
update_blastdb.pl nt nr　＃更新本地blast的核酸及蛋白库
blastn -query Spinach_Maxbin_binned.concat.fasta -db ~/softwar/ncbi-blast-2.7.1+/bin/nt 
-nums_threads 30 -max_target_seqs 3 -out Spinach.blast


diamond输出m8格式的本地blastp的比对结果，用awk命令提取第二列蛋白id进行爬虫注释可视化
#爬虫-宏基因组注释
#1.网页批量爬取蛋白信息
library(rvest)
myid<-read.table("protein_seq.txt")
myAnno<-NULL
for (i in 1:nrow(myid)) {
  seqid<-myid[i,1]
  url<-paste("https://www.ncbi.nlm.nih.gov/protein/",seqid,sep = "")
  Info<-read_html(url)
  inf<-Info%>%
    html_nodes(css = "#maincontent h1")%>%
    html_text()
  myAnno<-c(myAnno,inf)
}
#2.正则表达式提取物种信息
myAnno2<-NULL
for (i in 1:length(myAnno)) {
  part<-strsplit(myAnno[i],"")
  for (j in 1:nchar(myAnno[i])) {
    if(part[[1]][j]=="["){
      myAnno2<-c(myAnno2,substring(myAnno[i],first = j+1,last = (nchar(myAnno[i])-1)))}
    else{myAnno2<-myAnno2}
  }
}
#3.统计物种数量
#把同一物种的不同株系合并为同一物种
TotalAnno<-NULL
for (i in 1:length(myAnno2)) {
  TotalAnno<-c(TotalAnno,paste(strsplit(myAnno2[i]," ")[[1]][1],strsplit(myAnno2[i]," ")[[1]][2],sep = " "))
}
TotalAnno<-TotalAnno[na.rm=TRUE]
#正式统计
Spesta<-list()
for (i in 1:length(TotalAnno)) {
    Spe<-TotalAnno[i]
    Spesta[[Spe]]<-c(Spesta[[Spe]],i)
}
Spenum<-data.frame()
Speci<-as.vector(names(Spesta))
for (j in 1:length(Speci)) {
  Spenum[j,1]<-Speci[j]
  Spenum[j,2]<-length(Spesta[[j]])
}
#4.可视化
#词云可视化
library(wordcloud2)
wordcloud2(Spenum)
#ggplot2可视化
library(ggplot2)
p<-ggplot(Spenum,mapping=aes(x=Spenum[,1],y=Spenum[,2],fill=Spenum[,2]))+geom_bar(stat = "identity")
p<-p+theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5))
#5.个性化分析
#5.1多样本共同菌种差异分析
#共同菌种提取
commSpe<-NULL
for (i in 1:nrow(myfish3num)) {
  for (j in 1:nrow(myfish4num)) {
    if(myfish3num[i,1]==myfish4num[j,1]){
     commSpe<-c(commSpe,myfish3num[i,1],myfish3num[i,2],myfish4num[j,2])
    }
  }
}
commSpe<-matrix(commSpe,ncol = 3,byrow = T)
commSpe<-as.data.frame(commSpe)
write.table(commSpe,"Diffmicrobio.txt",sep = "\t")#用Excel打开更改一些格式
#独立菌种提取
diffSpe<-NULL
commNam<-commSpe[,1]
z<-NULL
for (i in 1:nrow(myfish3num)) {
  if(myfish3num[i,1] %in% commNam){z<-z+1}
  else{diffSpe<-c(diffSpe,myfish3num[i,1],myfish3num[i,2])}
}
diffSpe<-matrix(diffSpe,ncol = 2,byrow = T)
colnames(diffSpe)<-c("Name","num")
diffSpe2<-NULL
x<-NULL
for (j in 1:nrow(myfish4num)) {
  if(myfish4num[j,1] %in% commNam){x<-x+1}
  else{diffSpe2<-c(diffSpe2,myfish4num[j,1],myfish4num[j,2])}
}
diffSpe2<-matrix(diffSpe2,ncol = 2,byrow = T)
colnames(diffSpe2)<-c("Name","num")
#差异分析
mySpe<-read.table("Diffmicrobio.txt",header = T,sep = "\t")
mySpe<-as.matrix(mySpe)
rownames(mySpe)<-mySpe[,1]
mySpe<-mySpe[,2:ncol(mySpe)]
dimnames<-list(rownames(mySpe),colnames(mySpe))
mySpe<-matrix(as.numeric(as.matrix(mySpe)),nrow=nrow(mySpe),dimnames=dimnames(mySpe))
#无重复数据差异分析
library(edgeR)
mygroup<-DGEList(counts = mySpe,group = 1:2)#传递列表
mygroup<-calcNormFactors(mygroup)#标准化mygroup，使用TMM方法
mygroup<-estimateCommonDisp(mygroup) #计算普通的离散度
etgroup<-exactTest(mygroup,dispersion = 0.1^2)#检验差异
results<-etgroup$table#输出显著性结果
write.table(results,"菌种差异显著性.txt",sep="\t")
topTags(etgroup,n=50)
is.de<-decideTestsDGE(etgroup)
plotMD(etgroup, status=is.de, values=c(1,-1), col=c("red","blue"),legend="topright")#对菌种差异度画图
#热图
Bacheatmap<-mygroup$counts
library(pheatmap)
mat<-Bacheatmap
pheatmap(mat,scale="column",cluster_col=FALSE,border_color="grey60",fontsize = 10,
         cellwidth=120,cellheight = 12,treeheight_row=80,main = "DiffBac",
         color = colorRampPalette(c("navy", "white", "firebrick3"))(50))

#Krnoa数据预处理,将Kraken结果强行转化为Krona识别结果
mykrna<-read.table("Burger2_kraken_report.txt",sep = "\t")
mykrna<-as.matrix(mykrna)
mykrona<-NULL
krona<-NULL
for (i in 1:nrow(mykrna)) {
  b<-NULL
  a<-NULL
  c<-NULL
  a<-strsplit(mykrna[i,1],"")
  for (j in 1:(length(a$V1)-1)) {
    if(a$V1[j]=="s" && a$V1[j+1]=="_"){
      for (k in 1:length(a$V1)) {
        b<-paste(b,a$V1[k],sep = "")
      }
    }
    else{c<-c+1}
  }
  krona<-c(krona,b)
}
for (i in 1:length(krona)) {
  for (j in 1:nrow(mykrna)) {
    if(krona[i]==mykrna[j,1]){
      mykrona<-c(mykrona,mykrna[j,2],krona[i])
    }
  }
}
mykrona<-matrix(mykrona,ncol = 2,byrow = T)
mykrona<-as.data.frame(mykrona)
write.table(mykrona,"Krona测试.txt",sep = "\t")






